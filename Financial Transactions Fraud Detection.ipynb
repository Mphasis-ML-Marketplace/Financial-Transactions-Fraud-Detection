{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, tune, and deploy a custom ML model using Financial Transactions Fraud Detection Algorithm from AWS Marketplace \n",
    "\n",
    "\n",
    "This solution is a deep learning based algorithm capable of training on transactional data, to identify spurious transactions.\n",
    "\n",
    "\n",
    "\n",
    "This sample notebook shows you how to train a custom ML model using Financial Transactions Fraud Detection from AWS Marketplace.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to For Seller to update: Financial Transactions Fraud Detection. \n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "\t1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "\t1. [Configure and visualize train and test dataset](#B.-Configure-and-visualize-train-and-test-dataset)\n",
    "\t1. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Train a machine learning model](#3:-Train-a-machine-learning-model)\n",
    "\t1. [Set up environment](#3.1-Set-up-environment)\n",
    "\t1. [Train a model](#3.2-Train-a-model)\n",
    "1. [Deploy model and verify results](#4:-Deploy-model-and-verify-results)\n",
    "    1. [Deploy trained model](#A.-Deploy-trained-model)\n",
    "    1. [Create input payload](#B.-Create-input-payload)\n",
    "    1. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "    1. [Visualize output](#D.-Visualize-output)\n",
    "    1. [Calculate relevant metrics](#E.-Calculate-relevant-metrics)\n",
    "    1. [Delete the endpoint](#F.-Delete-the-endpoint)\n",
    "1. [Tune your model! (optional)](#5:-Tune-your-model!-(optional))\n",
    "\t1. [Tuning Guidelines](#A.-Tuning-Guidelines)\n",
    "\t1. [Define Tuning configuration](#B.-Define-Tuning-configuration)\n",
    "\t1. [Run a model tuning job](#C.-Run-a-model-tuning-job)\n",
    "1. [Perform Batch inference](#6.-Perform-Batch-inference)\n",
    "1. [Clean-up](#7.-Clean-up)\n",
    "\t1. [Delete the model](#A.-Delete-the-model)\n",
    "\t1. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "\n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "1. Open the algorithm listing page Financial Transactions Fraud Detection\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_arn='arn:aws:sagemaker:us-east-2:786796469737:algorithm/fraud-fin-tensor-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "from IPython.display import Image\n",
    "from PIL import Image as ImageEdit\n",
    "import urllib.request\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm requires data in the format as decribed for best results \n",
    "\n",
    "1. Input data should be in binarized format to train and learn the patterns \n",
    "\n",
    "1. Build the binary variables judiciously and develop binary encoded columns, rather generating one-hot binary variables \n",
    "\n",
    "1. Keep the ratio of fraudulent data to non-fraudulent more then 1:1000 \n",
    "\n",
    "1. Try to incorporate as much patterns from non-fraudulent data as possible to increase out of sample accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Configure and visualize train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset='train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset='test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_0</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>date_0</th>\n",
       "      <th>date_1</th>\n",
       "      <th>date_2</th>\n",
       "      <th>date_3</th>\n",
       "      <th>date_4</th>\n",
       "      <th>...</th>\n",
       "      <th>amt___3</th>\n",
       "      <th>amt___4</th>\n",
       "      <th>amt___5</th>\n",
       "      <th>amt___6</th>\n",
       "      <th>amt___7</th>\n",
       "      <th>amt___8</th>\n",
       "      <th>swap_diff__0</th>\n",
       "      <th>swap_diff__1</th>\n",
       "      <th>swap_diff__2</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_0  month_1  month_2  month_3  month_4  date_0  date_1  date_2  \\\n",
       "0        0        0        0        0        1       0       0       0   \n",
       "1        0        0        0        1        0       0       0       0   \n",
       "2        0        0        0        1        1       0       0       0   \n",
       "3        0        0        1        0        0       0       0       0   \n",
       "4        0        0        1        0        1       0       0       0   \n",
       "\n",
       "   date_3  date_4  ...  amt___3  amt___4  amt___5  amt___6  amt___7  amt___8  \\\n",
       "0       0       0  ...        0        0        0        0        0        1   \n",
       "1       0       1  ...        0        0        0        0        1        0   \n",
       "2       0       1  ...        0        0        0        0        1        1   \n",
       "3       1       0  ...        0        0        0        1        0        0   \n",
       "4       1       0  ...        0        0        0        1        0        1   \n",
       "\n",
       "   swap_diff__0  swap_diff__1  swap_diff__2  is_fraud  \n",
       "0             0             0             1         0  \n",
       "1             0             1             0         0  \n",
       "2             0             0             1         0  \n",
       "3             0             0             1         0  \n",
       "4             0             1             1         0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(training_dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-2-786796469737'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "bucket=sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=sagemaker_session.upload_data(training_dataset, bucket=bucket, key_prefix='financial_fraud')\n",
    "test_data=sagemaker_session.upload_data(test_dataset, bucket=bucket, key_prefix='financial_fraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that dataset is available in an accessible Amazon S3 bucket, we are ready to train a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = 's3://{}/financial_fraud/{}'.format(bucket, 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find more information about hyperparametes in **Hyperparameters** section of Financial Transactions Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define hyperparameters\n",
    "hyperparameters={\"epoches\":100,\"batch_size\":10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on creating an `Estimator` object, see [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-10 17:38:51 Starting - Starting the training job...\n",
      "2021-05-10 17:39:15 Starting - Launching requested ML instancesProfilerReport-1620668331: InProgress\n",
      "......\n",
      "2021-05-10 17:40:15 Starting - Preparing the instances for training...\n",
      "2021-05-10 17:40:52 Downloading - Downloading input data...\n",
      "2021-05-10 17:41:15 Training - Downloading the training image...\n",
      "2021-05-10 17:41:51 Training - Training image download completed. Training in progress..\u001b[34m2021-05-10 17:41:52.358827: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-05-10 17:41:52.358868: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-05-10 17:41:56.089488: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-05-10 17:41:56.091815: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-05-10 17:41:56.091838: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-05-10 17:41:56.092013: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-127-166.us-east-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-05-10 17:41:56.093101: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2021-05-10 17:41:56.093839: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34mTrain Confusion Matrix: \u001b[0m\n",
      "\u001b[34m[[9024    0]\n",
      " [   5  445]]\u001b[0m\n",
      "\u001b[34mTest Confusion Matrix: \u001b[0m\n",
      "\u001b[34m[[9024    0]\n",
      " [   5  445]]\u001b[0m\n",
      "\n",
      "2021-05-10 17:48:24 Uploading - Uploading generated training model\n",
      "2021-05-10 17:48:24 Completed - Training job completed\n",
      "Training seconds: 452\n",
      "Billable seconds: 452\n"
     ]
    }
   ],
   "source": [
    "#Create an estimator object for running a training job\n",
    "estimator = sage.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name=\"financial-fraud-training\",\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m5.large',\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large'\n",
    ")\n",
    "#Run the training job.\n",
    "estimator.fit({\"training\": training_data,\"test\":test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [blog-post](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/) for more information how to visualize metrics during the process. You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Deploy model and verify results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can deploy the model for performing real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='financial_fraud_inference'\n",
    "\n",
    "content_type='text/csv'\n",
    "\n",
    "real_time_inference_instance_type='ml.m5.large'\n",
    "batch_transform_inference_instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Deploy trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "-------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = estimator.deploy(1, real_time_inference_instance_type, serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint is created, you can perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"infrence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\"\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"infrence.csv\"\n",
    "output_file_name = \"result.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"application/json\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name $predictor.endpoint \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type $content_type \\\n",
    "    --region $sagemaker_session.boto_region_name \\\n",
    "    $output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\"\n"
     ]
    }
   ],
   "source": [
    "with open(\"result.txt\",\"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. you can terminate the same to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is an experiment, you do not need to run a hyperparameter tuning job. However, if you would like to see how to tune a model trained using a third-party algorithm with Amazon SageMaker's hyperparameter tuning functionality, you can run the optional tuning step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform Batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/financial_fraud_inference/infrence.csv\n"
     ]
    }
   ],
   "source": [
    "#upload the batch-transform job input files to S3\n",
    "transform_input_folder = \"infrence.csv\"\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name) \n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "........................\n",
      ".\u001b[34m * Serving Flask app \"serve\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[35m * Serving Flask app \"serve\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/May/2021 18:33:00] \"#033[37mGET /ping HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/May/2021 18:33:00] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/May/2021 18:33:01] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [10/May/2021 18:33:00] \"#033[37mGET /ping HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [10/May/2021 18:33:00] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [10/May/2021 18:33:01] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[32m2021-05-10T18:33:00.830:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m * Serving Flask app \"serve\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[35m * Serving Flask app \"serve\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/May/2021 18:33:00] \"#033[37mGET /ping HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/May/2021 18:33:00] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/May/2021 18:33:01] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [10/May/2021 18:33:00] \"#033[37mGET /ping HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [10/May/2021 18:33:00] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [10/May/2021 18:33:01] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
      "\u001b[32m2021-05-10T18:33:00.830:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Run the batch-transform job\n",
    "transformer = estimator.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-786796469737/financial-fraud-training-2021-05-10-18-29-02-689'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output is available on following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The function delete_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
